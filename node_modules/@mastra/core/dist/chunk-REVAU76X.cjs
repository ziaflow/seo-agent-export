'use strict';

var chunkUU5L5GDY_cjs = require('./chunk-UU5L5GDY.cjs');
var chunkWM4VQWOZ_cjs = require('./chunk-WM4VQWOZ.cjs');
var crypto = require('crypto');
var anthropicV5 = require('@ai-sdk/anthropic-v5');
var googleV5 = require('@ai-sdk/google-v5');
var openaiCompatibleV5 = require('@ai-sdk/openai-compatible-v5');
var openaiV5 = require('@ai-sdk/openai-v5');
var xaiV5 = require('@ai-sdk/xai-v5');
var aiSdkProviderV5 = require('@openrouter/ai-sdk-provider-v5');

// src/llm/model/gateway-resolver.ts
function parseModelRouterId(routerId, gatewayPrefix) {
  if (gatewayPrefix && !routerId.startsWith(`${gatewayPrefix}/`)) {
    throw new Error(`Expected ${gatewayPrefix}/ in model router ID ${routerId}`);
  }
  const idParts = routerId.split("/");
  if (gatewayPrefix && idParts.length < 3) {
    throw new Error(
      `Expected atleast 3 id parts ${gatewayPrefix}/provider/model, but only saw ${idParts.length} in ${routerId}`
    );
  }
  const providerId = idParts.at(gatewayPrefix ? 1 : 0);
  const modelId = idParts.slice(gatewayPrefix ? 2 : 1).join(`/`);
  if (!routerId.includes(`/`) || !providerId || !modelId) {
    throw new Error(
      `Attempted to parse provider/model from ${routerId} but this ID doesn't appear to contain a provider`
    );
  }
  return {
    providerId,
    modelId
  };
}

// src/llm/model/gateways/base.ts
var MastraModelGateway = class {
};

// src/llm/model/gateways/constants.ts
var PROVIDERS_WITH_INSTALLED_PACKAGES = ["anthropic", "google", "openai", "openrouter", "xai"];
var EXCLUDED_PROVIDERS = ["github-copilot"];

// src/llm/model/gateways/models-dev.ts
var OPENAI_COMPATIBLE_OVERRIDES = {
  cerebras: {
    url: "https://api.cerebras.ai/v1"
  },
  mistral: {
    url: "https://api.mistral.ai/v1"
  },
  groq: {
    url: "https://api.groq.com/openai/v1"
  },
  togetherai: {
    url: "https://api.together.xyz/v1"
  },
  deepinfra: {
    url: "https://api.deepinfra.com/v1/openai"
  },
  perplexity: {
    url: "https://api.perplexity.ai"
  },
  vercel: {
    url: "https://ai-gateway.vercel.sh/v1",
    apiKeyEnvVar: "AI_GATEWAY_API_KEY"
  }
};
var ModelsDevGateway = class extends MastraModelGateway {
  name = "models.dev";
  prefix = void 0;
  // No prefix for registry gateway
  providerConfigs = {};
  constructor(providerConfigs) {
    super();
    if (providerConfigs) this.providerConfigs = providerConfigs;
  }
  async fetchProviders() {
    console.info("Fetching providers from models.dev API...");
    const response = await fetch("https://models.dev/api.json");
    if (!response.ok) {
      throw new Error(`Failed to fetch from models.dev: ${response.statusText}`);
    }
    const data = await response.json();
    const providerConfigs = {};
    for (const [providerId, providerInfo] of Object.entries(data)) {
      if (EXCLUDED_PROVIDERS.includes(providerId)) continue;
      if (!providerInfo || typeof providerInfo !== "object" || !providerInfo.models) continue;
      const normalizedId = providerId;
      const isOpenAICompatible = providerInfo.npm === "@ai-sdk/openai-compatible" || providerInfo.npm === "@ai-sdk/gateway" || // Vercel AI Gateway is OpenAI-compatible
      normalizedId in OPENAI_COMPATIBLE_OVERRIDES;
      const hasInstalledPackage = PROVIDERS_WITH_INSTALLED_PACKAGES.includes(providerId);
      const hasApiAndEnv = providerInfo.api && providerInfo.env && providerInfo.env.length > 0;
      if (isOpenAICompatible || hasInstalledPackage || hasApiAndEnv) {
        const modelIds = Object.keys(providerInfo.models).sort();
        const url = providerInfo.api || OPENAI_COMPATIBLE_OVERRIDES[normalizedId]?.url;
        if (!hasInstalledPackage && !url) {
          console.info(`Skipping ${normalizedId}: No API URL available`);
          continue;
        }
        const apiKeyEnvVar = providerInfo.env?.[0] || `${normalizedId.toUpperCase().replace(/-/g, "_")}_API_KEY`;
        const apiKeyHeader = !hasInstalledPackage ? OPENAI_COMPATIBLE_OVERRIDES[normalizedId]?.apiKeyHeader || "Authorization" : void 0;
        providerConfigs[normalizedId] = {
          url,
          apiKeyEnvVar,
          apiKeyHeader,
          name: providerInfo.name || providerId.charAt(0).toUpperCase() + providerId.slice(1),
          models: modelIds,
          docUrl: providerInfo.doc,
          // Include documentation URL if available
          gateway: `models.dev`
        };
      } else {
        console.info(`Skipped provider ${providerInfo.name}`);
      }
    }
    this.providerConfigs = providerConfigs;
    console.info(`Found ${Object.keys(providerConfigs).length} OpenAI-compatible providers`);
    console.info("Providers:", Object.keys(providerConfigs).sort());
    return providerConfigs;
  }
  buildUrl(routerId, envVars) {
    const { providerId } = parseModelRouterId(routerId);
    const config = this.providerConfigs[providerId];
    if (!config?.url) {
      return;
    }
    const baseUrlEnvVar = `${providerId.toUpperCase().replace(/-/g, "_")}_BASE_URL`;
    const customBaseUrl = envVars?.[baseUrlEnvVar] || process.env[baseUrlEnvVar];
    return customBaseUrl || config.url;
  }
  getApiKey(modelId) {
    const [provider, model] = modelId.split("/");
    if (!provider || !model) {
      throw new Error(`Could not identify provider from model id ${modelId}`);
    }
    const config = this.providerConfigs[provider];
    if (!config) {
      throw new Error(`Could not find config for provider ${provider} with model id ${modelId}`);
    }
    const apiKey = typeof config.apiKeyEnvVar === `string` ? process.env[config.apiKeyEnvVar] : void 0;
    if (!apiKey) {
      throw new Error(`Could not find API key process.env.${config.apiKeyEnvVar} for model id ${modelId}`);
    }
    return Promise.resolve(apiKey);
  }
  async resolveLanguageModel({
    modelId,
    providerId,
    apiKey
  }) {
    const baseURL = this.buildUrl(`${providerId}/${modelId}`);
    switch (providerId) {
      case "openai":
        return openaiV5.createOpenAI({ apiKey }).responses(modelId);
      case "gemini":
      case "google":
        return googleV5.createGoogleGenerativeAI({
          apiKey
        }).chat(modelId);
      case "anthropic":
        return anthropicV5.createAnthropic({ apiKey })(modelId);
      case "openrouter":
        return aiSdkProviderV5.createOpenRouter({ apiKey })(modelId);
      case "xai":
        return xaiV5.createXai({
          apiKey
        })(modelId);
      default:
        if (!baseURL) throw new Error(`No API URL found for ${providerId}/${modelId}`);
        return openaiCompatibleV5.createOpenAICompatible({ name: providerId, apiKey, baseURL }).chatModel(modelId);
    }
  }
};
var NetlifyGateway = class extends MastraModelGateway {
  name = "netlify";
  prefix = "netlify";
  // All providers will be prefixed with "netlify/"
  tokenCache = new chunkUU5L5GDY_cjs.InMemoryServerCache();
  async fetchProviders() {
    console.info("Fetching providers from Netlify AI Gateway...");
    const response = await fetch("https://api.netlify.com/api/v1/ai-gateway/providers");
    if (!response.ok) {
      throw new Error(`Failed to fetch from Netlify: ${response.statusText}`);
    }
    const data = await response.json();
    const netlify = {
      apiKeyEnvVar: ["NETLIFY_TOKEN", "NETLIFY_SITE_ID"],
      apiKeyHeader: "Authorization",
      // Netlify uses standard Bearer auth
      name: `Netlify`,
      gateway: `netlify`,
      models: [],
      docUrl: "https://docs.netlify.com/build/ai-gateway/overview/"
    };
    for (const [providerId, provider] of Object.entries(data.providers)) {
      for (const model of provider.models) {
        netlify.models.push(`${providerId}/${model}`);
      }
    }
    console.info(`Found ${Object.keys(data.providers).length} models via Netlify Gateway`);
    return { netlify };
  }
  async buildUrl(routerId, envVars) {
    const siteId = envVars?.["NETLIFY_SITE_ID"] || process.env["NETLIFY_SITE_ID"];
    const netlifyToken = envVars?.["NETLIFY_TOKEN"] || process.env["NETLIFY_TOKEN"];
    if (!netlifyToken) {
      throw new chunkWM4VQWOZ_cjs.MastraError({
        id: "NETLIFY_GATEWAY_NO_TOKEN",
        domain: "LLM",
        category: "UNKNOWN",
        text: `Missing NETLIFY_TOKEN environment variable required for model: ${routerId}`
      });
    }
    if (!siteId) {
      throw new chunkWM4VQWOZ_cjs.MastraError({
        id: "NETLIFY_GATEWAY_NO_SITE_ID",
        domain: "LLM",
        category: "UNKNOWN",
        text: `Missing NETLIFY_SITE_ID environment variable required for model: ${routerId}`
      });
    }
    try {
      const tokenData = await this.getOrFetchToken(siteId, netlifyToken);
      return tokenData.url.endsWith(`/`) ? tokenData.url.substring(0, tokenData.url.length - 1) : tokenData.url;
    } catch (error) {
      throw new chunkWM4VQWOZ_cjs.MastraError({
        id: "NETLIFY_GATEWAY_TOKEN_ERROR",
        domain: "LLM",
        category: "UNKNOWN",
        text: `Failed to get Netlify AI Gateway token for model ${routerId}: ${error instanceof Error ? error.message : String(error)}`
      });
    }
  }
  /**
   * Get cached token or fetch a new site-specific AI Gateway token from Netlify
   */
  async getOrFetchToken(siteId, netlifyToken) {
    const cacheKey = `netlify-token:${siteId}:${netlifyToken}`;
    const cached = await this.tokenCache.get(cacheKey);
    if (cached && cached.expiresAt > Date.now() / 1e3 + 60) {
      return { token: cached.token, url: cached.url };
    }
    const response = await fetch(`https://api.netlify.com/api/v1/sites/${siteId}/ai-gateway/token`, {
      method: "GET",
      headers: {
        Authorization: `Bearer ${netlifyToken}`
      }
    });
    if (!response.ok) {
      const error = await response.text();
      throw new Error(`Failed to get Netlify AI Gateway token: ${response.status} ${error}`);
    }
    const tokenResponse = await response.json();
    await this.tokenCache.set(cacheKey, {
      token: tokenResponse.token,
      url: tokenResponse.url,
      expiresAt: tokenResponse.expires_at
    });
    return { token: tokenResponse.token, url: tokenResponse.url };
  }
  /**
   * Get cached token or fetch a new site-specific AI Gateway token from Netlify
   */
  async getApiKey(modelId) {
    const siteId = process.env["NETLIFY_SITE_ID"];
    const netlifyToken = process.env["NETLIFY_TOKEN"];
    if (!netlifyToken) {
      throw new chunkWM4VQWOZ_cjs.MastraError({
        id: "NETLIFY_GATEWAY_NO_TOKEN",
        domain: "LLM",
        category: "UNKNOWN",
        text: `Missing NETLIFY_TOKEN environment variable required for model: ${modelId}`
      });
    }
    if (!siteId) {
      throw new chunkWM4VQWOZ_cjs.MastraError({
        id: "NETLIFY_GATEWAY_NO_SITE_ID",
        domain: "LLM",
        category: "UNKNOWN",
        text: `Missing NETLIFY_SITE_ID environment variable required for model: ${modelId}`
      });
    }
    try {
      return (await this.getOrFetchToken(siteId, netlifyToken)).token;
    } catch (error) {
      throw new chunkWM4VQWOZ_cjs.MastraError({
        id: "NETLIFY_GATEWAY_TOKEN_ERROR",
        domain: "LLM",
        category: "UNKNOWN",
        text: `Failed to get Netlify AI Gateway token for model ${modelId}: ${error instanceof Error ? error.message : String(error)}`
      });
    }
  }
  async resolveLanguageModel({
    modelId,
    providerId,
    apiKey
  }) {
    const baseURL = await this.buildUrl(`${providerId}/${modelId}`);
    switch (providerId) {
      case "openai":
        return openaiV5.createOpenAI({ apiKey, baseURL }).responses(modelId);
      case "gemini":
        return googleV5.createGoogleGenerativeAI({
          baseURL: `${baseURL}/v1beta/`,
          apiKey,
          headers: {
            "user-agent": "google-genai-sdk/"
          }
        }).chat(modelId);
      case "anthropic":
        return anthropicV5.createAnthropic({
          apiKey,
          baseURL: `${baseURL}/v1/`,
          headers: {
            "anthropic-version": "2023-06-01",
            "user-agent": "anthropic/"
          }
        })(modelId);
      default:
        return openaiCompatibleV5.createOpenAICompatible({ name: providerId, apiKey, baseURL }).chatModel(modelId);
    }
  }
};

// src/llm/model/gateways/index.ts
function findGatewayForModel(gatewayId, gateways2) {
  const prefixedGateway = gateways2.find((g) => g.prefix && gatewayId.startsWith(`${g.prefix}/`));
  if (prefixedGateway) {
    return prefixedGateway;
  }
  const unprefixedGateways = gateways2.filter((g) => !g.prefix);
  for (const gateway of unprefixedGateways) {
    return gateway;
  }
  throw new chunkWM4VQWOZ_cjs.MastraError({
    id: "MODEL_ROUTER_NO_GATEWAY_FOUND",
    category: "USER",
    domain: "MODEL_ROUTER",
    text: `No Mastra model router gateway found for model id ${gatewayId}`
  });
}

// src/llm/model/provider-registry.generated.ts
var PROVIDER_REGISTRY = {
  "moonshotai-cn": {
    url: "https://api.moonshot.cn/v1",
    apiKeyEnvVar: "MOONSHOT_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Moonshot AI (China)",
    models: ["kimi-k2-0711-preview", "kimi-k2-0905-preview", "kimi-k2-turbo-preview"],
    docUrl: "https://platform.moonshot.cn/docs/api/chat",
    gateway: "models.dev"
  },
  lucidquery: {
    url: "https://lucidquery.com/api/v1",
    apiKeyEnvVar: "LUCIDQUERY_API_KEY",
    apiKeyHeader: "Authorization",
    name: "LucidQuery AI",
    models: ["lucidnova-rf1-100b", "lucidquery-nexus-coder"],
    docUrl: "https://lucidquery.com/api/docs",
    gateway: "models.dev"
  },
  moonshotai: {
    url: "https://api.moonshot.ai/v1",
    apiKeyEnvVar: "MOONSHOT_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Moonshot AI",
    models: ["kimi-k2-0711-preview", "kimi-k2-0905-preview", "kimi-k2-turbo-preview"],
    docUrl: "https://platform.moonshot.ai/docs/api/chat",
    gateway: "models.dev"
  },
  "zai-coding-plan": {
    url: "https://api.z.ai/api/coding/paas/v4",
    apiKeyEnvVar: "ZHIPU_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Z.AI Coding Plan",
    models: ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"],
    docUrl: "https://docs.z.ai/devpack/overview",
    gateway: "models.dev"
  },
  alibaba: {
    url: "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
    apiKeyEnvVar: "DASHSCOPE_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Alibaba",
    models: ["qwen3-coder-plus"],
    docUrl: "https://www.alibabacloud.com/help/en/model-studio/models",
    gateway: "models.dev"
  },
  xai: {
    apiKeyEnvVar: "XAI_API_KEY",
    name: "xAI",
    models: [
      "grok-2",
      "grok-2-1212",
      "grok-2-latest",
      "grok-2-vision",
      "grok-2-vision-1212",
      "grok-2-vision-latest",
      "grok-3",
      "grok-3-fast",
      "grok-3-fast-latest",
      "grok-3-latest",
      "grok-3-mini",
      "grok-3-mini-fast",
      "grok-3-mini-fast-latest",
      "grok-3-mini-latest",
      "grok-4",
      "grok-4-fast",
      "grok-4-fast-non-reasoning",
      "grok-beta",
      "grok-code-fast-1",
      "grok-vision-beta"
    ],
    docUrl: "https://docs.x.ai/docs/models",
    gateway: "models.dev"
  },
  nvidia: {
    url: "https://integrate.api.nvidia.com/v1",
    apiKeyEnvVar: "NVIDIA_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Nvidia",
    models: [
      "black-forest-labs/flux.1-dev",
      "deepseek-ai/deepseek-v3.1",
      "google/gemma-3-27b-it",
      "microsoft/phi-4-mini-instruct",
      "moonshotai/kimi-k2-instruct",
      "nvidia/cosmos-nemotron-34b",
      "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "nvidia/nemoretriever-ocr-v1",
      "nvidia/parakeet-tdt-0.6b-v2",
      "openai/gpt-oss-120b",
      "openai/whisper-large-v3",
      "qwen/qwen3-235b-a22b",
      "qwen/qwen3-coder-480b-a35b-instruct"
    ],
    docUrl: "https://docs.api.nvidia.com/nim/",
    gateway: "models.dev"
  },
  upstage: {
    url: "https://api.upstage.ai",
    apiKeyEnvVar: "UPSTAGE_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Upstage",
    models: ["solar-mini", "solar-pro2"],
    docUrl: "https://developers.upstage.ai/docs/apis/chat",
    gateway: "models.dev"
  },
  groq: {
    url: "https://api.groq.com/openai/v1",
    apiKeyEnvVar: "GROQ_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Groq",
    models: [
      "deepseek-r1-distill-llama-70b",
      "gemma2-9b-it",
      "llama-3.1-8b-instant",
      "llama-3.3-70b-versatile",
      "llama-guard-3-8b",
      "llama3-70b-8192",
      "llama3-8b-8192",
      "meta-llama/llama-4-maverick-17b-128e-instruct",
      "meta-llama/llama-4-scout-17b-16e-instruct",
      "meta-llama/llama-guard-4-12b",
      "mistral-saba-24b",
      "moonshotai/kimi-k2-instruct",
      "moonshotai/kimi-k2-instruct-0905",
      "openai/gpt-oss-120b",
      "openai/gpt-oss-20b",
      "qwen-qwq-32b",
      "qwen/qwen3-32b"
    ],
    docUrl: "https://console.groq.com/docs/models",
    gateway: "models.dev"
  },
  mistral: {
    url: "https://api.mistral.ai/v1",
    apiKeyEnvVar: "MISTRAL_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Mistral",
    models: [
      "codestral-latest",
      "devstral-medium-2507",
      "devstral-small-2505",
      "devstral-small-2507",
      "magistral-medium-latest",
      "magistral-small",
      "ministral-3b-latest",
      "ministral-8b-latest",
      "mistral-large-latest",
      "mistral-medium-2505",
      "mistral-medium-2508",
      "mistral-medium-latest",
      "mistral-nemo",
      "mistral-small-latest",
      "open-mistral-7b",
      "open-mixtral-8x22b",
      "open-mixtral-8x7b",
      "pixtral-12b",
      "pixtral-large-latest"
    ],
    docUrl: "https://docs.mistral.ai/getting-started/models/",
    gateway: "models.dev"
  },
  vercel: {
    url: "https://ai-gateway.vercel.sh/v1",
    apiKeyEnvVar: "AI_GATEWAY_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Vercel AI Gateway",
    models: [
      "amazon/nova-lite",
      "amazon/nova-micro",
      "amazon/nova-pro",
      "anthropic/claude-3-5-haiku",
      "anthropic/claude-3-haiku",
      "anthropic/claude-3-opus",
      "anthropic/claude-3.5-sonnet",
      "anthropic/claude-3.7-sonnet",
      "anthropic/claude-4-1-opus",
      "anthropic/claude-4-opus",
      "anthropic/claude-4-sonnet",
      "anthropic/claude-4.5-sonnet",
      "cerebras/qwen3-coder",
      "deepseek/deepseek-r1",
      "deepseek/deepseek-r1-distill-llama-70b",
      "google/gemini-2.0-flash",
      "google/gemini-2.0-flash-lite",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro",
      "meta/llama-3.3-70b",
      "meta/llama-4-maverick",
      "meta/llama-4-scout",
      "mistral/codestral",
      "mistral/magistral-medium",
      "mistral/magistral-small",
      "mistral/ministral-3b",
      "mistral/ministral-8b",
      "mistral/mistral-large",
      "mistral/mistral-small",
      "mistral/mixtral-8x22b-instruct",
      "mistral/pixtral-12b",
      "mistral/pixtral-large",
      "moonshotai/kimi-k2",
      "morph/morph-v3-fast",
      "morph/morph-v3-large",
      "openai/gpt-4-turbo",
      "openai/gpt-4.1",
      "openai/gpt-4.1-mini",
      "openai/gpt-4.1-nano",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/gpt-5",
      "openai/gpt-5-codex",
      "openai/gpt-5-mini",
      "openai/gpt-5-nano",
      "openai/gpt-oss-120b",
      "openai/gpt-oss-20b",
      "openai/o1",
      "openai/o3",
      "openai/o3-mini",
      "openai/o4-mini",
      "vercel/v0-1.0-md",
      "vercel/v0-1.5-md",
      "xai/grok-2",
      "xai/grok-2-vision",
      "xai/grok-3",
      "xai/grok-3-fast",
      "xai/grok-3-mini",
      "xai/grok-3-mini-fast",
      "xai/grok-4",
      "xai/grok-4-fast",
      "xai/grok-4-fast-non-reasoning",
      "xai/grok-code-fast-1"
    ],
    docUrl: "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
    gateway: "models.dev"
  },
  deepseek: {
    url: "https://api.deepseek.com",
    apiKeyEnvVar: "DEEPSEEK_API_KEY",
    apiKeyHeader: "Authorization",
    name: "DeepSeek",
    models: ["deepseek-chat", "deepseek-reasoner"],
    docUrl: "https://platform.deepseek.com/api-docs/pricing",
    gateway: "models.dev"
  },
  "alibaba-cn": {
    url: "https://dashscope.aliyuncs.com/compatible-mode/v1",
    apiKeyEnvVar: "DASHSCOPE_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Alibaba (China)",
    models: ["qwen3-coder-plus"],
    docUrl: "https://www.alibabacloud.com/help/en/model-studio/models",
    gateway: "models.dev"
  },
  venice: {
    url: "https://api.venice.ai/api/v1",
    apiKeyEnvVar: "VENICE_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Venice AI",
    models: [
      "deepseek-coder-v2-lite",
      "deepseek-r1-671b",
      "dolphin-2.9.2-qwen2-72b",
      "llama-3.1-405b",
      "llama-3.2-3b",
      "llama-3.3-70b",
      "mistral-31-24b",
      "qwen-2.5-coder-32b",
      "qwen-2.5-qwq-32b",
      "qwen-2.5-vl",
      "qwen3-235b",
      "qwen3-4b",
      "venice-uncensored"
    ],
    docUrl: "https://docs.venice.ai",
    gateway: "models.dev"
  },
  chutes: {
    url: "https://llm.chutes.ai/v1",
    apiKeyEnvVar: "CHUTES_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Chutes",
    models: [
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-30B-A3B",
      "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "chutesai/Devstral-Small-2505",
      "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
      "deepseek-ai/DeepSeek-R1-0528",
      "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "deepseek-ai/DeepSeek-V3-0324",
      "deepseek-ai/DeepSeek-V3.1",
      "deepseek-ai/DeepSeek-V3.1-Terminus",
      "deepseek-ai/DeepSeek-V3.1-turbo",
      "deepseek-ai/DeepSeek-V3.1:THINKING",
      "meituan-longcat/LongCat-Flash-Chat-FP8",
      "moonshotai/Kimi-Dev-72B",
      "moonshotai/Kimi-K2-Instruct-0905",
      "moonshotai/Kimi-K2-Instruct-75k",
      "moonshotai/Kimi-VL-A3B-Thinking",
      "openai/gpt-oss-120b",
      "tngtech/DeepSeek-R1T-Chimera",
      "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "zai-org/GLM-4.5-Air",
      "zai-org/GLM-4.5-FP8",
      "zai-org/GLM-4.5-turbo",
      "zai-org/GLM-4.6-FP8"
    ],
    docUrl: "https://llm.chutes.ai/v1/models",
    gateway: "models.dev"
  },
  cortecs: {
    url: "https://api.cortecs.ai/v1",
    apiKeyEnvVar: "CORTECS_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Cortecs",
    models: [
      "claude-sonnet-4",
      "deepseek-v3-0324",
      "gemini-2.5-pro",
      "gpt-4.1",
      "gpt-oss-120b",
      "kimi-k2-instruct",
      "llama-3.1-405b-instruct",
      "nova-pro-v1",
      "qwen3-32b",
      "qwen3-coder-480b-a35b-instruct"
    ],
    docUrl: "https://api.cortecs.ai/v1/models",
    gateway: "models.dev"
  },
  "github-models": {
    url: "https://models.github.ai/inference",
    apiKeyEnvVar: "GITHUB_TOKEN",
    apiKeyHeader: "Authorization",
    name: "GitHub Models",
    models: [
      "ai21-labs/ai21-jamba-1.5-large",
      "ai21-labs/ai21-jamba-1.5-mini",
      "cohere/cohere-command-a",
      "cohere/cohere-command-r",
      "cohere/cohere-command-r-08-2024",
      "cohere/cohere-command-r-plus",
      "cohere/cohere-command-r-plus-08-2024",
      "core42/jais-30b-chat",
      "deepseek/deepseek-r1",
      "deepseek/deepseek-r1-0528",
      "deepseek/deepseek-v3-0324",
      "meta/llama-3.2-11b-vision-instruct",
      "meta/llama-3.2-90b-vision-instruct",
      "meta/llama-3.3-70b-instruct",
      "meta/llama-4-maverick-17b-128e-instruct-fp8",
      "meta/llama-4-scout-17b-16e-instruct",
      "meta/meta-llama-3-70b-instruct",
      "meta/meta-llama-3-8b-instruct",
      "meta/meta-llama-3.1-405b-instruct",
      "meta/meta-llama-3.1-70b-instruct",
      "meta/meta-llama-3.1-8b-instruct",
      "microsoft/mai-ds-r1",
      "microsoft/phi-3-medium-128k-instruct",
      "microsoft/phi-3-medium-4k-instruct",
      "microsoft/phi-3-mini-128k-instruct",
      "microsoft/phi-3-mini-4k-instruct",
      "microsoft/phi-3-small-128k-instruct",
      "microsoft/phi-3-small-8k-instruct",
      "microsoft/phi-3.5-mini-instruct",
      "microsoft/phi-3.5-moe-instruct",
      "microsoft/phi-3.5-vision-instruct",
      "microsoft/phi-4",
      "microsoft/phi-4-mini-instruct",
      "microsoft/phi-4-mini-reasoning",
      "microsoft/phi-4-multimodal-instruct",
      "microsoft/phi-4-reasoning",
      "mistral-ai/codestral-2501",
      "mistral-ai/ministral-3b",
      "mistral-ai/mistral-large-2411",
      "mistral-ai/mistral-medium-2505",
      "mistral-ai/mistral-nemo",
      "mistral-ai/mistral-small-2503",
      "openai/gpt-4.1",
      "openai/gpt-4.1-mini",
      "openai/gpt-4.1-nano",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/o1",
      "openai/o1-mini",
      "openai/o1-preview",
      "openai/o3",
      "openai/o3-mini",
      "openai/o4-mini",
      "xai/grok-3",
      "xai/grok-3-mini"
    ],
    docUrl: "https://docs.github.com/en/github-models",
    gateway: "models.dev"
  },
  togetherai: {
    url: "https://api.together.xyz/v1",
    apiKeyEnvVar: "TOGETHER_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Together AI",
    models: [
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "deepseek-ai/DeepSeek-R1",
      "deepseek-ai/DeepSeek-V3",
      "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "moonshotai/Kimi-K2-Instruct",
      "openai/gpt-oss-120b"
    ],
    docUrl: "https://docs.together.ai/docs/serverless-models",
    gateway: "models.dev"
  },
  baseten: {
    url: "https://inference.baseten.co/v1",
    apiKeyEnvVar: "BASETEN_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Baseten",
    models: ["Qwen3/Qwen3-Coder-480B-A35B-Instruct", "moonshotai/Kimi-K2-Instruct-0905"],
    docUrl: "https://docs.baseten.co/development/model-apis/overview",
    gateway: "models.dev"
  },
  huggingface: {
    url: "https://router.huggingface.co/v1",
    apiKeyEnvVar: "HF_TOKEN",
    apiKeyHeader: "Authorization",
    name: "Hugging Face",
    models: [
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "deepseek-ai/DeepSeek-R1-0528",
      "deepseek-ai/Deepseek-V3-0324",
      "moonshotai/Kimi-K2-Instruct",
      "moonshotai/Kimi-K2-Instruct-0905",
      "zai-org/GLM-4.5",
      "zai-org/GLM-4.5-Air",
      "zai-org/GLM-4.6"
    ],
    docUrl: "https://huggingface.co/docs/inference-providers",
    gateway: "models.dev"
  },
  opencode: {
    url: "https://opencode.ai/zen/v1",
    apiKeyEnvVar: "OPENCODE_API_KEY",
    apiKeyHeader: "Authorization",
    name: "OpenCode Zen",
    models: [
      "claude-3-5-haiku",
      "claude-opus-4-1",
      "claude-sonnet-4",
      "claude-sonnet-4-5",
      "code-supernova",
      "glm-4.6",
      "gpt-5",
      "gpt-5-codex",
      "grok-code",
      "kimi-k2",
      "qwen3-coder",
      "qwen3-max"
    ],
    docUrl: "https://opencode.ai/docs/zen",
    gateway: "models.dev"
  },
  fastrouter: {
    url: "https://go.fastrouter.ai/api/v1",
    apiKeyEnvVar: "FASTROUTER_API_KEY",
    apiKeyHeader: "Authorization",
    name: "FastRouter",
    models: [
      "anthropic/claude-opus-4.1",
      "anthropic/claude-sonnet-4",
      "deepseek-ai/deepseek-r1-distill-llama-70b",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro",
      "moonshotai/kimi-k2",
      "openai/gpt-4.1",
      "openai/gpt-5",
      "openai/gpt-5-mini",
      "openai/gpt-5-nano",
      "openai/gpt-oss-120b",
      "openai/gpt-oss-20b",
      "qwen/qwen3-coder",
      "x-ai/grok-4"
    ],
    docUrl: "https://fastrouter.ai/models",
    gateway: "models.dev"
  },
  google: {
    apiKeyEnvVar: "GOOGLE_GENERATIVE_AI_API_KEY",
    name: "Google",
    models: [
      "gemini-1.5-flash",
      "gemini-1.5-flash-8b",
      "gemini-1.5-pro",
      "gemini-2.0-flash",
      "gemini-2.0-flash-lite",
      "gemini-2.5-flash",
      "gemini-2.5-flash-lite",
      "gemini-2.5-flash-lite-preview-06-17",
      "gemini-2.5-flash-lite-preview-09-2025",
      "gemini-2.5-flash-preview-04-17",
      "gemini-2.5-flash-preview-05-20",
      "gemini-2.5-flash-preview-09-2025",
      "gemini-2.5-pro",
      "gemini-2.5-pro-preview-05-06",
      "gemini-2.5-pro-preview-06-05",
      "gemini-flash-latest",
      "gemini-flash-lite-latest",
      "gemini-live-2.5-flash-preview-native-audio"
    ],
    docUrl: "https://ai.google.dev/gemini-api/docs/pricing",
    gateway: "models.dev"
  },
  inception: {
    url: "https://api.inceptionlabs.ai/v1/",
    apiKeyEnvVar: "INCEPTION_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Inception",
    models: ["mercury", "mercury-coder"],
    docUrl: "https://platform.inceptionlabs.ai/docs",
    gateway: "models.dev"
  },
  wandb: {
    url: "https://api.inference.wandb.ai/v1",
    apiKeyEnvVar: "WANDB_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Weights & Biases",
    models: [
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "deepseek-ai/DeepSeek-R1-0528",
      "deepseek-ai/DeepSeek-V3-0324",
      "meta-llama/Llama-3.1-8B-Instruct",
      "meta-llama/Llama-3.3-70B-Instruct",
      "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "microsoft/Phi-4-mini-instruct",
      "moonshotai/Kimi-K2-Instruct"
    ],
    docUrl: "https://weave-docs.wandb.ai/guides/integrations/inference/",
    gateway: "models.dev"
  },
  openai: {
    apiKeyEnvVar: "OPENAI_API_KEY",
    name: "OpenAI",
    models: [
      "codex-mini-latest",
      "gpt-3.5-turbo",
      "gpt-4",
      "gpt-4-turbo",
      "gpt-4.1",
      "gpt-4.1-mini",
      "gpt-4.1-nano",
      "gpt-4o",
      "gpt-4o-2024-05-13",
      "gpt-4o-2024-08-06",
      "gpt-4o-2024-11-20",
      "gpt-4o-mini",
      "gpt-5",
      "gpt-5-chat-latest",
      "gpt-5-codex",
      "gpt-5-mini",
      "gpt-5-nano",
      "o1",
      "o1-mini",
      "o1-preview",
      "o1-pro",
      "o3",
      "o3-deep-research",
      "o3-mini",
      "o3-pro",
      "o4-mini",
      "o4-mini-deep-research"
    ],
    docUrl: "https://platform.openai.com/docs/models",
    gateway: "models.dev"
  },
  "zhipuai-coding-plan": {
    url: "https://open.bigmodel.cn/api/coding/paas/v4",
    apiKeyEnvVar: "ZHIPU_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Zhipu AI Coding Plan",
    models: ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"],
    docUrl: "https://docs.bigmodel.cn/cn/coding-plan/overview",
    gateway: "models.dev"
  },
  perplexity: {
    url: "https://api.perplexity.ai",
    apiKeyEnvVar: "PERPLEXITY_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Perplexity",
    models: ["sonar", "sonar-pro", "sonar-reasoning", "sonar-reasoning-pro"],
    docUrl: "https://docs.perplexity.ai",
    gateway: "models.dev"
  },
  openrouter: {
    url: "https://openrouter.ai/api/v1",
    apiKeyEnvVar: "OPENROUTER_API_KEY",
    name: "OpenRouter",
    models: [
      "anthropic/claude-3.5-haiku",
      "anthropic/claude-3.7-sonnet",
      "anthropic/claude-opus-4",
      "anthropic/claude-opus-4.1",
      "anthropic/claude-sonnet-4",
      "anthropic/claude-sonnet-4.5",
      "cognitivecomputations/dolphin3.0-mistral-24b",
      "cognitivecomputations/dolphin3.0-r1-mistral-24b",
      "deepseek/deepseek-chat-v3-0324",
      "deepseek/deepseek-chat-v3.1",
      "deepseek/deepseek-r1-0528-qwen3-8b:free",
      "deepseek/deepseek-r1-0528:free",
      "deepseek/deepseek-r1-distill-llama-70b",
      "deepseek/deepseek-r1-distill-qwen-14b",
      "deepseek/deepseek-r1:free",
      "deepseek/deepseek-v3-base:free",
      "deepseek/deepseek-v3.1-terminus",
      "featherless/qwerky-72b",
      "google/gemini-2.0-flash-001",
      "google/gemini-2.0-flash-exp:free",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro",
      "google/gemini-2.5-pro-preview-05-06",
      "google/gemini-2.5-pro-preview-06-05",
      "google/gemma-2-9b-it:free",
      "google/gemma-3-12b-it",
      "google/gemma-3-27b-it",
      "google/gemma-3n-e4b-it",
      "google/gemma-3n-e4b-it:free",
      "meta-llama/llama-3.2-11b-vision-instruct",
      "meta-llama/llama-3.3-70b-instruct:free",
      "meta-llama/llama-4-scout:free",
      "microsoft/mai-ds-r1:free",
      "mistralai/codestral-2508",
      "mistralai/devstral-medium-2507",
      "mistralai/devstral-small-2505",
      "mistralai/devstral-small-2505:free",
      "mistralai/devstral-small-2507",
      "mistralai/mistral-7b-instruct:free",
      "mistralai/mistral-medium-3",
      "mistralai/mistral-medium-3.1",
      "mistralai/mistral-nemo:free",
      "mistralai/mistral-small-3.1-24b-instruct",
      "mistralai/mistral-small-3.2-24b-instruct",
      "mistralai/mistral-small-3.2-24b-instruct:free",
      "moonshotai/kimi-dev-72b:free",
      "moonshotai/kimi-k2",
      "moonshotai/kimi-k2-0905",
      "moonshotai/kimi-k2:free",
      "nousresearch/deephermes-3-llama-3-8b-preview",
      "nousresearch/hermes-4-405b",
      "nousresearch/hermes-4-70b",
      "openai/gpt-4.1",
      "openai/gpt-4.1-mini",
      "openai/gpt-4o-mini",
      "openai/gpt-5",
      "openai/gpt-5-chat",
      "openai/gpt-5-codex",
      "openai/gpt-5-mini",
      "openai/gpt-5-nano",
      "openai/gpt-oss-120b",
      "openai/gpt-oss-20b",
      "openai/o4-mini",
      "openrouter/cypher-alpha:free",
      "openrouter/horizon-alpha",
      "openrouter/horizon-beta",
      "openrouter/sonoma-dusk-alpha",
      "openrouter/sonoma-sky-alpha",
      "qwen/qwen-2.5-coder-32b-instruct",
      "qwen/qwen2.5-vl-32b-instruct:free",
      "qwen/qwen2.5-vl-72b-instruct",
      "qwen/qwen2.5-vl-72b-instruct:free",
      "qwen/qwen3-14b:free",
      "qwen/qwen3-235b-a22b-07-25",
      "qwen/qwen3-235b-a22b-07-25:free",
      "qwen/qwen3-235b-a22b-thinking-2507",
      "qwen/qwen3-235b-a22b:free",
      "qwen/qwen3-30b-a3b-instruct-2507",
      "qwen/qwen3-30b-a3b:free",
      "qwen/qwen3-32b:free",
      "qwen/qwen3-8b:free",
      "qwen/qwen3-coder",
      "qwen/qwen3-coder:free",
      "qwen/qwen3-max",
      "qwen/qwen3-next-80b-a3b-instruct",
      "qwen/qwq-32b:free",
      "rekaai/reka-flash-3",
      "sarvamai/sarvam-m:free",
      "thudm/glm-z1-32b:free",
      "tngtech/deepseek-r1t2-chimera:free",
      "x-ai/grok-3",
      "x-ai/grok-3-beta",
      "x-ai/grok-3-mini",
      "x-ai/grok-3-mini-beta",
      "x-ai/grok-4",
      "x-ai/grok-4-fast",
      "x-ai/grok-4-fast:free",
      "x-ai/grok-code-fast-1",
      "z-ai/glm-4.5",
      "z-ai/glm-4.5-air",
      "z-ai/glm-4.5-air:free",
      "z-ai/glm-4.5v",
      "z-ai/glm-4.6"
    ],
    docUrl: "https://openrouter.ai/models",
    gateway: "models.dev"
  },
  synthetic: {
    url: "https://api.synthetic.new/v1",
    apiKeyEnvVar: "SYNTHETIC_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Synthetic",
    models: [
      "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
      "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
      "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
      "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "hf:deepseek-ai/DeepSeek-R1",
      "hf:deepseek-ai/DeepSeek-R1-0528",
      "hf:deepseek-ai/DeepSeek-V3",
      "hf:deepseek-ai/DeepSeek-V3-0324",
      "hf:deepseek-ai/DeepSeek-V3.1",
      "hf:deepseek-ai/DeepSeek-V3.1-Terminus",
      "hf:meta-llama/Llama-3.1-405B-Instruct",
      "hf:meta-llama/Llama-3.1-70B-Instruct",
      "hf:meta-llama/Llama-3.1-8B-Instruct",
      "hf:meta-llama/Llama-3.3-70B-Instruct",
      "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "hf:moonshotai/Kimi-K2-Instruct",
      "hf:moonshotai/Kimi-K2-Instruct-0905",
      "hf:openai/gpt-oss-120b",
      "hf:zai-org/GLM-4.5",
      "hf:zai-org/GLM-4.6"
    ],
    docUrl: "https://synthetic.new/pricing",
    gateway: "models.dev"
  },
  deepinfra: {
    url: "https://api.deepinfra.com/v1/openai",
    apiKeyEnvVar: "DEEPINFRA_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Deep Infra",
    models: [
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
      "moonshotai/Kimi-K2-Instruct",
      "zai-org/GLM-4.5"
    ],
    docUrl: "https://deepinfra.com/models",
    gateway: "models.dev"
  },
  zhipuai: {
    url: "https://open.bigmodel.cn/api/paas/v4",
    apiKeyEnvVar: "ZHIPU_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Zhipu AI",
    models: ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"],
    docUrl: "https://docs.z.ai/guides/overview/pricing",
    gateway: "models.dev"
  },
  submodel: {
    url: "https://llm.submodel.ai/v1",
    apiKeyEnvVar: "SUBMODEL_INSTAGEN_ACCESS_KEY",
    apiKeyHeader: "Authorization",
    name: "submodel",
    models: [
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "deepseek-ai/DeepSeek-R1-0528",
      "deepseek-ai/DeepSeek-V3-0324",
      "deepseek-ai/DeepSeek-V3.1",
      "openai/gpt-oss-120b",
      "zai-org/GLM-4.5-Air",
      "zai-org/GLM-4.5-FP8"
    ],
    docUrl: "https://submodel.gitbook.io",
    gateway: "models.dev"
  },
  zai: {
    url: "https://api.z.ai/api/paas/v4",
    apiKeyEnvVar: "ZHIPU_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Z.AI",
    models: ["glm-4.5", "glm-4.5-air", "glm-4.5-flash", "glm-4.5v", "glm-4.6"],
    docUrl: "https://docs.z.ai/guides/overview/pricing",
    gateway: "models.dev"
  },
  inference: {
    url: "https://inference.net/v1",
    apiKeyEnvVar: "INFERENCE_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Inference",
    models: [
      "google/gemma-3",
      "meta/llama-3.1-8b-instruct",
      "meta/llama-3.2-11b-vision-instruct",
      "meta/llama-3.2-1b-instruct",
      "meta/llama-3.2-3b-instruct",
      "mistral/mistral-nemo-12b-instruct",
      "osmosis/osmosis-structure-0.6b",
      "qwen/qwen-2.5-7b-vision-instruct",
      "qwen/qwen3-embedding-4b"
    ],
    docUrl: "https://inference.net/models",
    gateway: "models.dev"
  },
  requesty: {
    url: "https://router.requesty.ai/v1",
    apiKeyEnvVar: "REQUESTY_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Requesty",
    models: [
      "anthropic/claude-3-7-sonnet",
      "anthropic/claude-4-sonnet-20250522",
      "anthropic/claude-opus-4",
      "anthropic/claude-opus-4-1-20250805",
      "google/gemini-2.5-flash",
      "google/gemini-2.5-pro",
      "openai/gpt-4.1",
      "openai/gpt-4.1-mini",
      "openai/gpt-4o-mini",
      "openai/gpt-5",
      "openai/gpt-5-mini",
      "openai/gpt-5-nano",
      "openai/o4-mini"
    ],
    docUrl: "https://requesty.ai/solution/llm-routing/models",
    gateway: "models.dev"
  },
  morph: {
    url: "https://api.morphllm.com/v1",
    apiKeyEnvVar: "MORPH_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Morph",
    models: ["auto", "morph-v3-fast", "morph-v3-large"],
    docUrl: "https://docs.morphllm.com/api-reference/introduction",
    gateway: "models.dev"
  },
  lmstudio: {
    url: "http://127.0.0.1:1234/v1",
    apiKeyEnvVar: "LMSTUDIO_API_KEY",
    apiKeyHeader: "Authorization",
    name: "LMStudio",
    models: ["openai/gpt-oss-20b", "qwen/qwen3-30b-a3b-2507", "qwen/qwen3-coder-30b"],
    docUrl: "https://lmstudio.ai/models",
    gateway: "models.dev"
  },
  anthropic: {
    apiKeyEnvVar: "ANTHROPIC_API_KEY",
    name: "Anthropic",
    models: [
      "claude-3-5-haiku-20241022",
      "claude-3-5-sonnet-20240620",
      "claude-3-5-sonnet-20241022",
      "claude-3-7-sonnet-20250219",
      "claude-3-haiku-20240307",
      "claude-3-opus-20240229",
      "claude-3-sonnet-20240229",
      "claude-opus-4-1-20250805",
      "claude-opus-4-20250514",
      "claude-sonnet-4-20250514",
      "claude-sonnet-4-5-20250929"
    ],
    docUrl: "https://docs.anthropic.com/en/docs/about-claude/models",
    gateway: "models.dev"
  },
  "fireworks-ai": {
    url: "https://api.fireworks.ai/inference/v1/",
    apiKeyEnvVar: "FIREWORKS_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Fireworks AI",
    models: [
      "accounts/fireworks/models/deepseek-r1-0528",
      "accounts/fireworks/models/deepseek-v3-0324",
      "accounts/fireworks/models/deepseek-v3p1",
      "accounts/fireworks/models/glm-4p5",
      "accounts/fireworks/models/glm-4p5-air",
      "accounts/fireworks/models/gpt-oss-120b",
      "accounts/fireworks/models/gpt-oss-20b",
      "accounts/fireworks/models/kimi-k2-instruct",
      "accounts/fireworks/models/qwen3-235b-a22b",
      "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct"
    ],
    docUrl: "https://fireworks.ai/docs/",
    gateway: "models.dev"
  },
  modelscope: {
    url: "https://api-inference.modelscope.cn/v1",
    apiKeyEnvVar: "MODELSCOPE_API_KEY",
    apiKeyHeader: "Authorization",
    name: "ModelScope",
    models: [
      "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "ZhipuAI/GLM-4.5"
    ],
    docUrl: "https://modelscope.cn/docs/model-service/API-Inference/intro",
    gateway: "models.dev"
  },
  llama: {
    url: "https://api.llama.com/compat/v1/",
    apiKeyEnvVar: "LLAMA_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Llama",
    models: [
      "cerebras-llama-4-maverick-17b-128e-instruct",
      "cerebras-llama-4-scout-17b-16e-instruct",
      "groq-llama-4-maverick-17b-128e-instruct",
      "llama-3.3-70b-instruct",
      "llama-3.3-8b-instruct",
      "llama-4-maverick-17b-128e-instruct-fp8",
      "llama-4-scout-17b-16e-instruct-fp8"
    ],
    docUrl: "https://llama.developer.meta.com/docs/models",
    gateway: "models.dev"
  },
  cerebras: {
    url: "https://api.cerebras.ai/v1",
    apiKeyEnvVar: "CEREBRAS_API_KEY",
    apiKeyHeader: "Authorization",
    name: "Cerebras",
    models: ["gpt-oss-120b", "qwen-3-235b-a22b-instruct-2507", "qwen-3-coder-480b"],
    docUrl: "https://inference-docs.cerebras.ai/models/overview",
    gateway: "models.dev"
  },
  netlify: {
    apiKeyEnvVar: ["NETLIFY_TOKEN", "NETLIFY_SITE_ID"],
    apiKeyHeader: "Authorization",
    name: "Netlify",
    gateway: "netlify",
    models: [
      "anthropic/claude-opus-4-20250514",
      "anthropic/claude-3-7-sonnet-20250219",
      "anthropic/claude-3-7-sonnet-latest",
      "anthropic/claude-3-haiku-20240307",
      "anthropic/claude-opus-4-1-20250805",
      "anthropic/claude-sonnet-4-5-20250929",
      "anthropic/claude-sonnet-4-20250514",
      "anthropic/claude-3-5-haiku-20241022",
      "anthropic/claude-3-5-haiku-latest",
      "gemini/gemini-2.0-flash-lite",
      "gemini/gemini-2.5-flash-image-preview",
      "gemini/gemini-2.5-pro",
      "gemini/gemini-flash-latest",
      "gemini/gemini-2.5-flash-preview-09-2025",
      "gemini/gemini-flash-lite-latest",
      "gemini/gemini-2.5-flash",
      "gemini/gemini-2.5-flash-lite-preview-09-2025",
      "gemini/gemini-2.5-flash-lite",
      "gemini/gemini-2.0-flash",
      "openai/gpt-4o",
      "openai/gpt-4o-mini",
      "openai/o4-mini",
      "openai/o3",
      "openai/gpt-5-pro",
      "openai/gpt-5",
      "openai/gpt-5-codex",
      "openai/gpt-5-mini",
      "openai/gpt-5-nano",
      "openai/gpt-4.1",
      "openai/o3-mini",
      "openai/codex-mini-latest",
      "openai/gpt-4.1-mini",
      "openai/gpt-4.1-nano"
    ],
    docUrl: "https://docs.netlify.com/build/ai-gateway/overview/"
  }
};
function getProviderConfig(providerId) {
  return PROVIDER_REGISTRY[providerId];
}
function parseModelString(modelString) {
  const firstSlashIndex = modelString.indexOf("/");
  if (firstSlashIndex !== -1) {
    const provider = modelString.substring(0, firstSlashIndex);
    const modelId = modelString.substring(firstSlashIndex + 1);
    if (provider && modelId) {
      return {
        provider,
        modelId
      };
    }
  }
  return {
    provider: null,
    modelId: modelString
  };
}

// src/llm/model/router.ts
function getStaticProvidersByGateway(name) {
  return Object.fromEntries(Object.entries(PROVIDER_REGISTRY).filter(([_provider, config]) => config.gateway === name));
}
var gateways = [new NetlifyGateway(), new ModelsDevGateway(getStaticProvidersByGateway(`models.dev`))];
var ModelRouterLanguageModel = class _ModelRouterLanguageModel {
  specificationVersion = "v2";
  defaultObjectGenerationMode = "json";
  supportsStructuredOutputs = true;
  supportsImageUrls = true;
  supportedUrls = {};
  modelId;
  provider;
  config;
  gateway;
  constructor(config) {
    if (typeof config === `string`) config = { id: config };
    const parsedConfig = { ...config, routerId: config.id };
    this.gateway = findGatewayForModel(config.id, gateways);
    const parsed = parseModelRouterId(config.id, this.gateway.prefix);
    this.provider = parsed.providerId || "openai-compatible";
    if (parsed.providerId && parsed.modelId !== config.id) {
      parsedConfig.id = parsed.modelId;
    }
    this.modelId = parsedConfig.id;
    this.config = parsedConfig;
    this.gateway = findGatewayForModel(parsedConfig.routerId, gateways);
  }
  async doGenerate() {
    throw new Error(
      "doGenerate is not supported by Mastra model router. Mastra only uses streaming (doStream) for all LLM calls."
    );
  }
  async doStream(options) {
    let apiKey;
    try {
      apiKey = await this.gateway.getApiKey(this.config.routerId);
    } catch (error) {
      return {
        stream: new ReadableStream({
          start(controller) {
            controller.enqueue({
              type: "error",
              error: error instanceof Error ? error.message : String(error)
            });
          }
        })
      };
    }
    const model = await this.resolveLanguageModel({
      apiKey,
      ...parseModelRouterId(this.config.routerId, this.gateway.prefix)
    });
    return model.doStream(options);
  }
  async resolveLanguageModel({
    modelId,
    providerId,
    apiKey
  }) {
    const key = crypto.createHash("sha256").update(this.gateway.name + modelId + providerId + apiKey).digest("hex");
    if (_ModelRouterLanguageModel.modelInstances.has(key)) return _ModelRouterLanguageModel.modelInstances.get(key);
    const modelInstance = await this.gateway.resolveLanguageModel({ modelId, providerId, apiKey });
    _ModelRouterLanguageModel.modelInstances.set(key, modelInstance);
    return modelInstance;
  }
  static modelInstances = /* @__PURE__ */ new Map();
};

exports.ModelRouterLanguageModel = ModelRouterLanguageModel;
exports.PROVIDER_REGISTRY = PROVIDER_REGISTRY;
exports.getProviderConfig = getProviderConfig;
exports.parseModelString = parseModelString;
//# sourceMappingURL=chunk-REVAU76X.cjs.map
//# sourceMappingURL=chunk-REVAU76X.cjs.map